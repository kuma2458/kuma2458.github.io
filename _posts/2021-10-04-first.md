---
title:  "과제1 텐서 소개"
---







### 텐서와 넘파이

```python
#텐서, 넘파이 설정
import tensorflow as tf
import numpy as np
```



> 	### 텐서란
>
> 일관된 유형을 가진 다차원 배열, 데이터 형식은 dtype으로 일관되어있으며 다양한 형식을 지원한다.
>
> 텐서는 넘파이로도 볼 수 있으며, 일종의 np.arrays와 같다
>
> 텐서는 파이썬의 숫자와 문자열같이 변경할 수 없으며, 내용을 업데이트 할 수 없어 내용을 바꾸려면 새로운 텐서를 만들어야 한다.



## 기본적인 텐서 정보 소개

- ##### 스칼라(순위-0 텐서)

```python
# 기본적으로 `int32`텐서로 작성되며, 이는 `dtype`에서 확인할 수 있다.
rank_0_tensor = tf.constant(4)
print(rank_0_tensor)
```

```python
>>> tf.Tensor(4, shape=(), dtype=int32)
```

>스칼라는 단일 값을 나타낼 때 쓰며, 행같은 축이 존재하지 않는다.
>
>0차원이라고 볼 수 있다. 
>
>축이 없어 다른 값들을 담기 힘들다.



- ##### 벡터(순위-1 텐서)

```python
# float 텐서를 만들어보자
rank_1_tensor = tf.constant([2.0, 3.0, 4.0])
print(rank_1_tensor)
```

```python
>>> tf.Tensor([2. 3. 4.], shape=(3,), dtype=float32)
```

> 벡터는 행으로 나타내지며,  한그룹의 데이터값들을 담을 수 있다.
>
> 스칼라보단 데이터값을 담는데 자유롭지만, 데이터 별로 기준을 잡아 분류할 수는 없다.



- ##### 행렬(순위-2 텐서)

```python
# float 텐서를 만들어보자
rank_1_tensor = tf.constant([2.0, 3.0, 4.0])
print(rank_1_tensor)
```

```python
>>> tf.Tensor([2. 3. 4.], shape=(3,), dtype=float32)
```

> 행렬은 행과 열로 나타내지며, 한 그룹의 데이터값을 담을 수 있으며 데이터들을 구분하여 분류할 수 있다.
>
> 벡터보다 더 많은 데이터를 담을 수 있다.



- ##### 더 많은 축을 사용하는 텐서

```python
# 여러개의 축(또는 "차원"이라고도 함)이 존재할 수도 있습니다
rank_3_tensor = tf.constant([
  [[0, 1, 2, 3, 4],
   [5, 6, 7, 8, 9]],
  [[10, 11, 12, 13, 14],
   [15, 16, 17, 18, 19]],
  [[20, 21, 22, 23, 24],
   [25, 26, 27, 28, 29]],])

print(rank_3_tensor)
```

```python
>>>	tf.Tensor(
[[[ 0  1  2  3  4]
  [ 5  6  7  8  9]]

 [[10 11 12 13 14]
  [15 16 17 18 19]]

 [[20 21 22 23 24]
  [25 26 27 28 29]]], shape=(3, 2, 5), dtype=int32)
```

>여기서는 행,열, 행렬을 담는 축 으로 총 3개의 축을 사용하여 행렬을 데이터로 담아서 벡터처럼 표현하였다.
>
>shap=(3,2,5)에서 
>3은 제일 큰 차원에서 봤을때 데이터의 개수이며, 
>2는 그 아래 차원에서 데이터의 값이 [0~4] [5~9] 로 2개,
>5는 마지막 차원에서 0,1,2,3,4 총 5개이므로 5로 표현되었다.
>
>앞에서부터 가장 큰 차원에서의 데이터 개수다



- ##### 메서드를 사용해 텐서를 Numpy 배열로 변환하기

> `np.array` 또는 `tensor.numpy` 메서드를 사용하여 변환 할 수 있다.

```python
#np.array 메서드로 변환하기
np.array(rank_2_tensor)
```

```python
>>> array([[1., 2.],
       [3., 4.],
       [5., 6.]], dtype=float16)
```

```python
#tensor.numpy 메서드로 변환하기
rank_2_tensor.numpy()
```

```python
array([[1., 2.],
       [3., 4.],
       [5., 6.]], dtype=float16)
```

> 두 메소드 다 같은 결과값을 가진다.
>
> 텐서와 같은 형태로 존재한다.



- ##### 텐서의 다양한 데이터 유형

> 텐서는 일반적으로 숫자형인 float와 int를 많이 사용하지만, `'복소수'` 나 `'문자열'`같은 다른 데이터 유형도 존재한다.



- ##### 특수 유형의 텐서들

> 기본적으로 `'tf.Tensor'` 클래스들은 텐서가 직사각형으로 길이가 같아야 한다.
>
> 그러나 직사각형 모양 말고도 다양한 형상의 텐서를 처리할 수 있는 `'비정형'`이나 `'희소'`같은 특수 유형의 텐서가 존재한다



- ##### 덧셈,요소별 곱셈,행렬 곱셈같은 기본 산술

```python
a = tf.constant([[1, 2],
                 [3, 4]])
b = tf.constant([[1, 1],
                 [1, 1]]) # `tf.ones([2,2])`으로도 작성 가능

print(tf.add(a, b), "\n") #덧셈
print(tf.multiply(a, b), "\n") #요소별 곱셈
print(tf.matmul(a, b), "\n") #행렬 곱셈
```

```python
>>> tf.Tensor(
[[2 3]
 [4 5]], shape=(2, 2), dtype=int32) #덧셈 결과

tf.Tensor(
[[1 2]
 [3 4]], shape=(2, 2), dtype=int32) #요소별 곱셈 결과

tf.Tensor(
[[3 3]
 [7 7]], shape=(2, 2), dtype=int32) #행렬 곱셈 결과
```

```python
print(a + b, "\n") # 요소별 덧셈
print(a * b, "\n") # 요소별 곱셈
print(a @ b, "\n") # 행렬 곱셈
```

```python
>>> tf.Tensor(
[[2 3]
 [4 5]], shape=(2, 2), dtype=int32) 

tf.Tensor(
[[1 2]
 [3 4]], shape=(2, 2), dtype=int32) 

tf.Tensor(
[[3 3]
 [7 7]], shape=(2, 2), dtype=int32)
```

> `tf.add`나 `tf.multiply` 같은 메서드로 수행할 수 있으며
> `+`나 `*` 같은 특수문자로도 표현할 수 있다.



- ##### 기본 산술 외 다양한 연산에도 텐서를 사용한다.

```python
c = tf.constant([[4.0, 5.0], [10.0, 1.0]])

# 데이터 중 가장 큰 값 찾기
print(tf.reduce_max(c))
# 가장 큰 값의 인덱스 출력
print(tf.argmax(c))
# 소프트맥스 적용
print(tf.nn.softmax(c))
```

```python
>>> 
tf.Tensor(10.0, shape=(), dtype=float32)
tf.Tensor([1 0], shape=(2,), dtype=int64)
tf.Tensor(
[[2.6894143e-01 7.3105854e-01]
 [9.9987662e-01 1.2339458e-04]], shape=(2, 2), dtype=float32)
```



- ##### 형상 정보

```python
rank_4_tensor = tf.zeros([3, 2, 4, 5])
```

```python
print("Type of every element:", rank_4_tensor.dtype) #요소들의 타입
print("Number of dimensions:", rank_4_tensor.ndim) #텐서의 순위
print("Shape of tensor:", rank_4_tensor.shape) #텐서의 형상
print("Elements along axis 0 of tensor:", rank_4_tensor.shape[0]) #0순위 차원의 길이
print("Elements along the last axis of tensor:", rank_4_tensor.shape[-1]) #마지막 순위 차원의 길이
print("Total number of elements (3*2*4*5): ", tf.size(rank_4_tensor).numpy()) #텐서의 크기
```

```python
>>>>
Type of every element: <dtype: 'float32'>
Number of dimensions: 4
Shape of tensor: (3, 2, 4, 5)
Elements along axis 0 of tensor: 3
Elements along the last axis of tensor: 5
Total number of elements (3*2*4*5):  120
```

> - 형상 : 텐서의 각 차원의 길이
>   위 텐서에서 형상은 `3, 2, 4, 5` 를 나타낸다.
> - 순위 : 텐서 축의 수
>   위 텐서에서 순위는 `3, 2, 4, 5`  총 4개의 축을 가지고 있다.
> - 축 또는 차원 : 텐서의 특정 차원
>   위 텐서에서 축 또는 차원은 `3 `, `2`, `4`, `5` 가 있다.
> - 크기 : 텐서의 총 항목 수, 곱 형상 벡터
>   위 텐서에서 크기는 ` 3*2*4*5` 으로 `120`이다



## 인덱싱

- #### 단일 축 인덱싱

---

> TensorFlow는 파이썬의 목록 또는 문자열 인덱싱과 같이 `표준 파이썬 인덱싱 규칙`과 `numpy 인덱싱의 기본 규칙`을 따른다.	
>
> - 인덱스는 0부터 시작한다
> - 음수 인덱스는 끝에서부터 거꾸로 계산된다
> - 콜론, `:`은 슬라이스 `start:stop:step`에 사용된다.



```python
rank_1_tensor = tf.constant([0, 1, 1, 2, 3, 5, 8, 13, 21, 34])
print(rank_1_tensor.numpy())
```

```python
>>> [ 0  1  1  2  3  5  8 13 21 34]
```

> 데이터 값들만 프린트된다



- ##### 스칼라를 사용하여 인덱싱 시 

```python
print("First:", rank_1_tensor[0].numpy()) #첫번째 값 출력
print("Second:", rank_1_tensor[1].numpy()) #두번째 값 출력
print("Last:", rank_1_tensor[-1].numpy()) #마지막 값 출력
```

```python
>>>
First: 0
Second: 1
Last: 34
```

>축이 제거되어 출력되는걸 볼 수 있다.
>
>[0] : 텐서의 첫번째 인덱스값인 0이 출력된다.
>[1] : 텐서의 두번째 값인 1이 출력된다.
>[-1] : 음수이기때문에 거꾸로 끝에서부터 첫번째값인 34가 출력된다



- ##### 슬라이스를 사용하여 인덱싱 시

```python
print("Everything:", rank_1_tensor[:].numpy()) #모든 데이터값 출력
print("Before 4:", rank_1_tensor[:4].numpy()) #인덱스 4 이전값인 4번째 데이터값까지 출력
print("From 4 to the end:", rank_1_tensor[4:].numpy()) #인덱스 4, 즉 5번째 데이터값부터 출력
print("From 2, before 7:", rank_1_tensor[2:7].numpy()) #인덱스 2부터 7, 즉 3번째부터 8번째 데이터값까지 출력
print("Every other item:", rank_1_tensor[::2].numpy()) #인덱스 값이 짝수인 데이터들만 출력
print("Reversed:", rank_1_tensor[::-1].numpy()) #역순으로 출력
```

```python
>>>
Everything: [ 0  1  1  2  3  5  8 13 21 34]
Before 4: [0 1 1 2]
From 4 to the end: [ 3  5  8 13 21 34]
From 2, before 7: [1 2 3 5 8]
Every other item: [ 0  1  3  8 21]
Reversed: [34 21 13  8  5  3  2  1  1  0]
```

> 슬라이스를 사용하면 축이 유지된다
>
> 스칼라보다 더 다양하게 표현이 가능하다.



- #### 다축 인덱싱

---

> 더 높은 순위의 텐서는 여러 인덱스를 전달하여 인덱싱된다.
>
> 단일축과 같은 규칙이 각 축, 차원에 적용된다.



```python
print(rank_2_tensor.numpy())
```

```python
>>> [[1. 2.]
 [3. 4.]
 [5. 6.]]
```

> 다축인 텐서의 모양이 출력된다



- ##### 각 인덱스에 정수를 전달할 시

```python
# 순위-2텐서인 행렬에서 단일값을 가져올 수 있다.
print(rank_2_tensor[1, 1].numpy())
```

```python
>>> 4.0
```

>축이 제거된 채로 결과값이 나온다.
>
>1행 1열의 값인 4.0이 출력된다.



- ##### 각 인덱스에 정수를 전달할 시

```python
# 텐서의 행과 열을 출력
print("Second row:", rank_2_tensor[1, :].numpy()) #2행의 모든 데이터값을 출력
print("Second column:", rank_2_tensor[:, 1].numpy()) #2열의 모든 데이터 값을 출력
print("Last row:", rank_2_tensor[-1, :].numpy()) #마지막 행의 모든 데이터 값을 출력
print("First item in last column:", rank_2_tensor[0, -1].numpy()) #첫번째행의 마지막 열 데이터 값을 출력
print("Skip the first row:") 
print(rank_2_tensor[1:, :].numpy(), "\n") #1행을 제외한 2행부터 마지막행의 모든 데이터값까지 출력
```

```python
>>> Second row: [3. 4.]
Second column: [2. 4. 6.]
Last row: [5. 6.]
First item in last column: 2.0
Skip the first row:
[[3. 4.]
 [5. 6.]]
```

>위와 같은 순위-2텐서 에서는 행렬에 대해
>
>`:` : 모든 값들
>`-1`: 마지막 행이나 열
>
>로 다양한 결과값들을 출력할수 있다.



- ##### 3축 텐서의 예

```python
print(rank_3_tensor[:, :, 4])
```

```python
>>> tf.Tensor(
[[ 4  9]
 [14 19]
 [24 29]], shape=(3, 2), dtype=int32)
```

>위에서 3축 텐서의 원본은
>
>```
>rank_3_tensor = tf.constant([
>  [[0, 1, 2, 3, 4],
>   [5, 6, 7, 8, 9]],
>  [[10, 11, 12, 13, 14],
>   [15, 16, 17, 18, 19]],
>  [[20, 21, 22, 23, 24],
>   [25, 26, 27, 28, 29]],])
>```
>
>으로, 3차원,2차원의 모든 값들 중 1차원에서 인덱스 4 값을 갖는 데이터들만 출력하도록 하였다.
>
>즉, 2축의 첫번째 값인 
>
>`[[0, 1, 2, 3, 4],[5, 6, 7, 8, 9]]  ` 에서 
>
>1축의 값인` [0, 1, 2, 3, 4]` 에서는 `[4]`를, 
>`[5, 6, 7, 8, 9]`에서는 `[9]`가 해당되므로 
>2차원으로 볼때 `[4,9]` 로 묶어서 출력된다.
>
>다른 2축들의 행렬도 이와 같이 계산하면
>
> `[[ 4 9]
> [14 19]
> [24 29]]` 라는 행렬이 나온다.



## 형상 조작하기

- ##### 텐서의 형상을 바꾸는건 매우 유용함

---

```python
# Shape는 각 차원의 크기를 표시하는 'TensorShape' 개체를 반환합니다.
var_x = tf.Variable(tf.constant([[1], [2], [3]]))
print(var_x.shape)
```

```python
>>> (3, 1)
```

```python
# 파이썬 리스트로도 변경할 수 있다.
print(var_x.shape.as_list())
```

```python
>>> [3, 1]
```

>벡터를 행렬처럼 표현했다.
>
>2축을 가진 3행1열 데이터 목록처럼 보인다.
>
>그러나 실제로는 1축 데이터이다.



- ##### 텐서를 새로운 형상으로 바꾸기

---

```python
# 텐서를 새로운 형상으로 만들 수 있습니다.
# 목록을 바꾸는 것뿐입니다.
reshaped = tf.reshape(var_x, [1, 3])
```

```python
print(var_x.shape)
print(reshaped.shape)
```

```python
>>>
(3, 1)
(1, 3)
```

>기존의 2축 3행1열의 형상을 갖던 텐서를 1행3열의 형상으로 바꿨다.
>
>바꾼 형상을 표현하면
>
>`[[1, 2, 3]]` 의 모습이다.



- ##### 형상을 새로만들면 세로운 새 텐서가 작성됨

---

```python
print(rank_3_tensor)
```

```python
>>>
tf.Tensor(
[[[ 0  1  2  3  4]
  [ 5  6  7  8  9]]

 [[10 11 12 13 14]
  [15 16 17 18 19]]

 [[20 21 22 23 24]
  [25 26 27 28 29]]], shape=(3, 2, 5), dtype=int32)
```



- ##### 데이터 순서 확인

---

```python
# `shape`에서 `-1`은 적재되어있는 순을 뜻한다.
print(tf.reshape(rank_3_tensor, [-1]))
```

```python
>>>
tf.Tensor(
[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29], shape=(30,), dtype=int32)
```

>reshape에서 `[-1]`옵션을 주면 적재되어있는 순서대로 나열된다.



- ##### `tf.reshape`의 합리적 용도

---

```python
print(tf.reshape(rank_3_tensor, [3*2, 5]), "\n") #인접한 3과 2축을 결합
print(tf.reshape(rank_3_tensor, [3, -1])) #인접한 2와 5축을 분해해 하나의 축으로 만듬
```

```python
>>>
tf.Tensor(
[[ 0  1  2  3  4]
 [ 5  6  7  8  9]
 [10 11 12 13 14]
 [15 16 17 18 19]
 [20 21 22 23 24]
 [25 26 27 28 29]], shape=(6, 5), dtype=int32) 

tf.Tensor(
[[ 0  1  2  3  4  5  6  7  8  9]
 [10 11 12 13 14 15 16 17 18 19]
 [20 21 22 23 24 25 26 27 28 29]], shape=(3, 10), dtype=int32)
```

>첫번째 코드에서는 1축은 유지한채, 2축과 3축을 통합하여 `6x5`형상의 텐서가 생성되었다.
>
>두번째 코드에서는 1축과 2축을 분해해 하나의 축에 통합시켜 `3x2`형상의 텐서가 생성되었다.



- ##### `tf.reshape`의 

---

```python
# 나쁜 예시, 하지마세요

# 축을 교환해서 reshape 할 수 없음
print(tf.reshape(rank_3_tensor, [2, 3, 5]), "\n") 

# 잘못된 예시
print(tf.reshape(rank_3_tensor, [5, 6]), "\n")

# 전혀 효과가 없습니다
try:
  tf.reshape(rank_3_tensor, [7, -1])
except Exception as e:
  print(f"{type(e).__name__}: {e}"
```

```python
>>>
tf.Tensor(
[[[ 0  1  2  3  4]
  [ 5  6  7  8  9]
  [10 11 12 13 14]]

 [[15 16 17 18 19]
  [20 21 22 23 24]
  [25 26 27 28 29]]], shape=(2, 3, 5), dtype=int32) 

tf.Tensor(
[[ 0  1  2  3  4  5]
 [ 6  7  8  9 10 11]
 [12 13 14 15 16 17]
 [18 19 20 21 22 23]
 [24 25 26 27 28 29]], shape=(5, 6), dtype=int32) 

>>>
InvalidArgumentError: Input to reshape is a tensor with 30 values, but the requested shape requires a multiple of 7 [Op:Reshape]
```

>`tf.reshape`으로는 축을 교환해서 형성할 수 없다.
>
>1번, 2번 코드들은 실행은 되지만, 유익한 코드는 아니다.
>
>3번째 코드는 데이터 개수가 30개인데 7개로 잘라서 축을 만드려고 하니 남는 데이터가 나와 오류가 발생했다.



## DTypes에 대한 추가 정보

- ##### `tf.tensor`의 데이터 유형을 검사하려면, `Tensor.dtype` 속성을 사용한다.

---

> Python 객체에서 `tf.Tensor`를 만들 때 직접 선택하여 데이터 유형을 지정할 수 있다.
>
> 직접 선택하지 않을 시, Tensorflow가 자동으로 데이터유형을 선택한다.
> Python 정수를 `tf.int32`로 지정하며, Python 부동 소수점 숫자를 `tf.float32`로 지정합니다.
>
> 그외 데이터유형들일 때는 Tensorflow는 Numpy가 배열로 변환할 때 사용하는 규칙과 동일하게 데이터유형을 지정합니다.



- ##### 유형별로 캐스팅

---

```python
the_f64_tensor = tf.constant([2.2, 3.3, 4.4], dtype=tf.float64)
the_f16_tensor = tf.cast(the_f64_tensor, dtype=tf.float16)

# 데이터유형을 'unit8' 로 지정하고 부동소수점값을 없앱니다.

the_u8_tensor = tf.cast(the_f16_tensor, dtype=tf.uint8)
print(the_u8_tensor)
```

```python
>>> tf.Tensor([2 3 4], shape=(3,), dtype=uint8)
```

>기존의 float64를 float16로도 변경할 수 있으며, `unit8` dtype으로 변경시켜 부동소수점 값들을 제거합니다.



## 브로드캐스팅

- ##### 특정 조건에서 작은 텐서는 연산을 실행할때 큰 텐서에 맞게 확장된다.

---

```python
x = tf.constant([1, 2, 3])

y = tf.constant(2)
z = tf.constant([2, 2, 2])

# 모두 다 같은 연산

print(tf.multiply(x, 2))
print(x * y)
print(x * z)
```

```python
>>>
tf.Tensor([2 4 6], shape=(3,), dtype=int32)
tf.Tensor([2 4 6], shape=(3,), dtype=int32)
tf.Tensor([2 4 6], shape=(3,), dtype=int32)
```

> `print(tf.multiply(x, 2))` 는 각 요소에 2를 곱한 값이며,
> `print(x * y)` 는 x텐서와 y텐서의 크기가 다르기 때문에 y텐서의 크기를 x텐서에 맞게 `([2])`로 키워준다.
> `print(x * z)`는 x텐서와 z텐서의 크기가 같으므로 확장하지않고 바로 연산이 가능하다.



- ##### 크기가 1인 축도 다른 인수와 일치하도록 확장함

---

```python
# 모두 다 같은 연산
x = tf.reshape(x,[3,1]) # 3행 1열의 형상으로 변경
y = tf.range(1, 5)
print(x, "\n")
print(y, "\n")
print(tf.multiply(x, y))
```

```python
>>>
tf.Tensor(
[[1]
 [2]
 [3]], shape=(3, 1), dtype=int32) 

tf.Tensor([1 2 3 4], shape=(4,), dtype=int32) 

tf.Tensor(
[[ 1  2  3  4]
 [ 2  4  6  8]
 [ 3  6  9 12]], shape=(3, 4), dtype=int32)
```

> `x = tf.reshape(x,[3,1])` 는 기존의 1행3열에서 3행1열의 형상으로 변경시킴
> `y = tf.range(1, 5)` 는 y텐서를 1부터 4까지의 데이터값으로 채우도록함
> x는 (3,1)이고 y는 (1,4)이므로 서로 곱셈 연산을하면 형상이 (3,4)인 텐서가 나온다.
>
> 다만 조심할점이 y가 (1,4)로 연산을 했지만, 실제로는 `([[1,2,3,4]])` 의 형상인 텐서가 아니라 `([1,2,3,4])`의 형상을 지닌 텐서다.



- ##### 브로드캐스팅이 없는 연산

---

```python
x_stretch = tf.constant([[1, 1, 1, 1],
                         [2, 2, 2, 2],
                         [3, 3, 3, 3]])

y_stretch = tf.constant([[1, 2, 3, 4],
                         [1, 2, 3, 4],
                         [1, 2, 3, 4]])

print(x_stretch * y_stretch)  # 연산자 오버로딩 발생
```

```python
>>>
tf.Tensor(
[[ 1  2  3  4]
 [ 2  4  6  8]
 [ 3  6  9 12]], shape=(3, 4), dtype=int32)
```

> 형상이 같기 때문에 추가적으로 브로드캐스팅이 필요한 연산이 아니다.



- ##### 브로드캐스팅은 연산시 시간과 공간을 효율적으로 사용할 수 있게 해준다.

---

```python
print(tf.broadcast_to(tf.constant([1, 2, 3]), [3, 3]))
```

```python
>>>
tf.Tensor(
[[1 2 3]
 [1 2 3]
 [1 2 3]], shape=(3, 3), dtype=int32)
```

> `tf.broadcast_to`를 사용하여 브로드캐스팅이 어떤 모습인지 확인이 가능함
>
> 수학적 op와 달리 메모리를 절약하기 위해 특별한 연산을 수행하지 않는다.
> 결과에서 텐서를 구체화한다.



## tf.convert_to_tensor

> `tf.matmul` 및 `tf.reshape`와 같은 대부분의 ops는 클래스 `tf.Tensor`의 인수를 사용한다.
> 이럴 경우 텐서 형상의 Python 객체가 수용된다.
>
> 대부분의 ops는 텐서가 아닌 인수에 대해 `convert_to_tensor`를 호출한다.
> 변환 레지스트리가 있어 NumPy의 `ndarray`, `TensorShape` , Python 목록 및 `tf.Variable`과 같은 대부분의 객체 클래스는 모두 자동으로 변환된다.



## 비정형 텐서

> 어떤 축을 따라 다양한 수의 요소를 가진 텐서를 '비정형(ragged)'라고 한다.
> 비정형 데이터에 `tf.ragged.RaggedTensor`를 사용한다.



- ##### 비정형 텐서는 정규 텐서로 표현할 수 없음

---

```python
ragged_list = [
    [0, 1, 2, 3],
    [4, 5],
    [6, 7, 8],
    [9]]
```

```python
try:
  tensor = tf.constant(ragged_list)
except Exception as e:
  print(f"{type(e).__name__}: {e}")
```

```python
>>> ValueError: Can't convert non-rectangular Python sequence to Tensor.
```

> 어느 한 축에 대해 수가 일정하지 않은 텐서는 정규 텐서로 표현할 수 없다.
>
> 정규 텐서로 표현하고싶으면 축의 요소 개수를 일치시켜야한다.



- ##### `tf.ragged.constant`를 사용하여 `tf.RaggedTensor`를 작성함

---

```python
ragged_tensor = tf.ragged.constant(ragged_list)
print(ragged_tensor)
```

```python
>>> <tf.RaggedTensor [[0, 1, 2, 3], [4, 5], [6, 7, 8], [9]]>
```

> `tf.ragged.constant`를 사용하여 비정형 텐서를 만들 수 있다.



- ##### `tf.RaggedTensor`에는 길이를 알 수 없는 축들이 존재 한다.

---

```python
print(ragged_tensor.shape)
```

```python
>>> (4, None)
```

> 2차원에서는 `[0, 1, 2, 3]`,`[4, 5]`,`[6, 7, 8]`,`[9]`  4개가 있는게 확인이 되지만,
> 1차원에서는 각각 4개, 2개, 3개, 1개로 일정하지 않아 하나의 값으로 반환할 수가 없어 `None` 값으로 출력된다.



## 문자열 텐서

- ##### 비정형 텐서는 정규 텐서로 표현할 수 없음

---

> `tf.string`은 `dtpye`의 한 종류로, 텐서에서 문자열과 같은 데이터를 나타낼 수 있다.
>
> 문자열은 원자성으로 Python 문자열과 같은 방식으로는 인덱싱할 수 없다.
> 문자열의 길이는 텐서의 축 중 하나가 아니다.



- ##### 스칼라 문자열 텐서

---

```python
# 텐서는 strings로 표현할 수 있으며, 밑의 텐서는 스칼라 문자열 텐서이다.
scalar_string_tensor = tf.constant("Gray wolf")
print(scalar_string_tensor)
```

```python
>>> tf.Tensor(b'Gray wolf', shape=(), dtype=string)
```

> 스칼라 문자열 텐서에서는 문자열을 축으로 계산하지않아 shape에서 축을 표현할 수 없다.



- ##### 문자열의 벡터

---

```python
# 길이가 다른 문자열 텐서가 세 개가 있어도 문제없다.
tensor_of_strings = tf.constant(["Gray wolf",
                                 "Quick brown fox",
                                 "Lazy dog"])
# 형상은 (3,)으로, 스칼라 문자열은 3개가 있지만, 각 문자열의 길이는 포함하지 않았다.
print(tensor_of_strings)
```

```python
>>> tf.Tensor([b'Gray wolf' b'Quick brown fox' b'Lazy dog'], shape=(3,), dtype=string)
```

> 요소는 3개가 있지만, 각 요소의 길이는 표현하지 않음
>
> 위 코드에서 `b` 접두사는 `tf.string` dtype이 유니코드 문자열이 아닌, 바이트 문자열인 것을 나타낸다.



- ##### 유니코드 문자 전달 시

---

```python
tf.constant("🥳👍")
```

```python
>>> <tf.Tensor: shape=(), dtype=string, numpy=b'\xf0\x9f\xa5\xb3\xf0\x9f\x91\x8d'>
```

> `UTF-8`로 인코딩된다.



- ##### 문자열이 있는 일부 기본 함수들

---

```python
# 분할을 사용해서 텐서를 나눌 수 있다.
print(tf.strings.split(scalar_string_tensor, sep=" "))
```

```python
>>> tf.Tensor([b'Gray' b'wolf'], shape=(2,), dtype=string)
```

```python
# 그러나 문자열 텐서를 나누면 'Ragged tensor'가 된다.
# 각 문자열은 서로 다른 부분으로 나뉘어질 수 있다.
print(tf.strings.split(tensor_of_strings))
```

```python
>>> <tf.RaggedTensor [[b'Gray', b'wolf'], [b'Quick', b'brown', b'fox'], [b'Lazy', b'dog']]>
```

> `tf.string.split`에서 확인할 수 있다.



- ##### `tf.string.to_number`:

---

```python
text = tf.constant("1 10 100")
print(tf.strings.to_number(tf.strings.split(text, " ")))
```

```python
>>> tf.Tensor([  1.  10. 100.], shape=(3,), dtype=float32)
```

> `tf.string.to_number`:는 문자열 텐서를 숫자형 텐서로 변환시킨다.
> 결과값에서 `dtype`이 `float32`로 바뀐것을 볼 수 있다.



- ##### `tf.cast`를 사용 시 문자열 텐서를 숫자로 변환할 수는 없지만, 바이트로 변환한 다음 숫자로 변환할 수 있습니다.

---

```python
byte_strings = tf.strings.bytes_split(tf.constant("Duck"))
byte_ints = tf.io.decode_raw(tf.constant("Duck"), tf.uint8)
print("Byte strings:", byte_strings)
print("Bytes:", byte_ints)
```

```python
>>> Byte strings: tf.Tensor([b'D' b'u' b'c' b'k'], shape=(4,), dtype=string)
Bytes: tf.Tensor([ 68 117  99 107], shape=(4,), dtype=uint8)
```

> "Duck"을 바이트 문자열로 변환한 후 `uint8`로 숫자로 변환하였다.



```python
# 또는 유니코드로 분할한 다음 디코딩합니다.
unicode_bytes = tf.constant("アヒル 🦆")
unicode_char_bytes = tf.strings.unicode_split(unicode_bytes, "UTF-8")
unicode_values = tf.strings.unicode_decode(unicode_bytes, "UTF-8")

print("\nUnicode bytes:", unicode_bytes)
print("\nUnicode chars:", unicode_char_bytes)
print("\nUnicode values:", unicode_values)
```

```python
>>>
Unicode bytes: tf.Tensor(b'\xe3\x82\xa2\xe3\x83\x92\xe3\x83\xab \xf0\x9f\xa6\x86', shape=(), dtype=string)

Unicode chars: tf.Tensor([b'\xe3\x82\xa2' b'\xe3\x83\x92' b'\xe3\x83\xab' b' ' b'\xf0\x9f\xa6\x86'], shape=(5,), dtype=string)

Unicode values: tf.Tensor([ 12450  12498  12523     32 129414], shape=(5,), dtype=int32)
```

> 유니코드로 변경 한 후 숫자로 변경할 수 있다.



## 희소 텐서

- ##### 때로 매우 넓은 임베드 공간같이 데이터가 존재하는 공간이 얼마 없는 텐서가 있다.

---

```python
# 희소 텐서는 메모리 효율적인 방식으로 인덱스별로 값을 저장한다.
sparse_tensor = tf.sparse.SparseTensor(indices=[[0, 0], [1, 2]],
                                       values=[1, 2],
                                       dense_shape=[3, 4])
print(sparse_tensor, "\n")

# 희소 텐서를 조밀한 텐서로 변환할 수 있다.
print(tf.sparse.to_dense(sparse_tensor))`	
```

```python
>>>
SparseTensor(indices=tf.Tensor(
[[0 0]
 [1 2]], shape=(2, 2), dtype=int64), values=tf.Tensor([1 2], shape=(2,), dtype=int32), dense_shape=tf.Tensor([3 4], shape=(2,), dtype=int64)) 

tf.Tensor(
[[1 0 0 0]
 [0 0 2 0]
 [0 0 0 0]], shape=(3, 4), dtype=int32)
```

> TensorFlow는 `tf.sparse.SparseTensor` 및 관련 연산을 지원하여 희소 데이터를 효율적으로 저장한다.
>
> 첫 번째 코드에서 `tf.sparse.SparseTensor`메서드를 사용해 `[0,0]` 과 `[1,2]` 에만 `[1,2]`라는 값이 존재하는 `shape=(3,4)`인 텐서를 만든다.
> 이런 데이터가 존재하는 거에 비해 빈 공간이 많은 텐서를 희소 텐서라 부른다.
> 희소 텐서는 표현해야하는것들만 표현을하고, 표현할 필요가 없는, 비어있는 공간은 굳이 표현을 하지않아 메모리를 절약한다.
>
> 두 번째 코드는 `tf.sparse.to_dense`메서드를 사용해 희소텐서를 우리가 알고 있는 일반적인 텐서의 모습으로 표현시켜준다.

