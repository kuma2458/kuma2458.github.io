### 기본설정

```python
# Python ≥3.5 is required
import sys
assert sys.version_info >= (3, 5)

# Scikit-Learn ≥0.20 is required
import sklearn
assert sklearn.__version__ >= "0.20"

# Common imports
import numpy as np
import os

# to make this notebook's output stable across runs
np.random.seed(42)

# To plot pretty figures
%matplotlib inline
import matplotlib as mpl
import matplotlib.pyplot as plt
mpl.rc('axes', labelsize=14)
mpl.rc('xtick', labelsize=12)
mpl.rc('ytick', labelsize=12)

# Where to save the figures
PROJECT_ROOT_DIR = "."
CHAPTER_ID = "decision_trees"
IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, "images", CHAPTER_ID)
os.makedirs(IMAGES_PATH, exist_ok=True)

def save_fig(fig_id, tight_layout=True, fig_extension="png", resolution=300):
    path = os.path.join(IMAGES_PATH, fig_id + "." + fig_extension)
    print("Saving figure", fig_id)
    if tight_layout:
        plt.tight_layout()
    plt.savefig(path, format=fig_extension, dpi=resolution)

from sklearn.datasets import load_iris
from sklearn.tree import DecisionTreeClassifier

iris = load_iris()
X = iris.data[:, 2:] # petal length and width
y = iris.target

tree_clf = DecisionTreeClassifier(max_depth=2, random_state=42)
tree_clf.fit(X, y)
```

# 1.랜덤 포레스트 모델 구현

### 데이터세트 준비

*   `make_moons(n_samples=500, noise=0.30)` 을 사용해 데이터셋을 생성합니다.

`random_state=42`를 추가해 동일한 결과가 나오도록 합니다.

```python
from sklearn.datasets import make_moons

X, y = make_moons(n_samples=500, noise=0.30, random_state=42)
```

*   `train_test_split()`을 사용해 훈련 세트와 테스트 세트로 나눕니다.

```python
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
```

### 결정트리 모델 준비

*  `DecisionTreeClassifier`의 최적의 매개변수를 찾기 위해 교차 검증과 함께 그리드 탐색을 수햅합니다(`GridSearchCV`를 사용하면 됩니다).



```python
from sklearn.model_selection import GridSearchCV

params = {'max_leaf_nodes': list(range(2, 100)), 'min_samples_split': [2, 3, 4]}
grid_search_cv = GridSearchCV(DecisionTreeClassifier(random_state=42), params, verbose=1, cv=3)

grid_search_cv.fit(X_train, y_train)

grid_search_cv.best_estimator_
```

```python
=>Fitting 3 folds for each of 294 candidates, totalling 882 fits
[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.
[Parallel(n_jobs=1)]: Done 882 out of 882 | elapsed:    1.3s finished
GridSearchCV(cv=3, error_score=nan,
             estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,
                                              criterion='gini', max_depth=None,
                                              max_features=None,
                                              max_leaf_nodes=None,
                                              min_impurity_decrease=0.0,
                                              min_impurity_split=None,
                                              min_samples_leaf=1,
                                              min_samples_split=2,
                                              min_weight_fraction_leaf=0.0,
                                              presort='deprecated',
                                              random_state=42,
                                              splitter='best'),
             iid='deprecated', n_jobs=None,
             param_grid={'max_leaf_nodes': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,
                                            13, 14, 15, 16, 17, 18, 19, 20, 21,
                                            22, 23, 24, 25, 26, 27, 28, 29, 30,
                                            31, ...],
                         'min_samples_split': [2, 3, 4]},
             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,
             scoring=None, verbose=1)
```

- 최적의 Max_leaf_nodes는 14로 나왔습니다.


*  찾은 매개변수를 사용해 전체 훈련 세트에 대해 모델을 훈련시키고 테스트 세트에서 성능을 측정합니다. 



기본적으로 `GridSearchCV`는 전체 교육 세트에 있는 최상의 모델을 교육하므로(`Refet=False`를 설정하여 변경할 수 있음) 다시 교육할 필요가 없습니다. 모델의 정확도를 간단하게 평가할 수 있습니다.

```python
from sklearn.metrics import accuracy_score

y_pred = grid_search_cv.predict(X_test)
accuracy_score(y_test, y_pred)
```

```python
=>	0.9
```

- 결정트리 모델의 정확도가 90%가 나온것을 알 수 있습니다.



### 랜덤포레스트 모델 구현

- 사이킷런의 `ShuffleSplit`을 사용해 나눴습니다.

```python
from sklearn.model_selection import ShuffleSplit

n_trees = 500 # 7장 랜덤포레스트 모델과 비교하기 위해 결정트리 개수를 500개로 통일함
n_instances = 100

mini_sets = []

rs = ShuffleSplit(n_splits=n_trees, test_size=len(X_train) - n_instances, random_state=42)
for mini_train_index, mini_test_index in rs.split(X_train):
    X_mini_train = X_train[mini_train_index]
    y_mini_train = y_train[mini_train_index]
    mini_sets.append((X_mini_train, y_mini_train))
```

* 이전 연습문제에서 찾은 최적의 매개변수를 사용해 각 서브셋에 결정 트리를 훈련시킵니다. 

* 최적의 매개변수는 Max_leaf_nodes = 14로 나왔습니다.

* 테스트 세트로 이 500개의 결정 트리를 평가합니다. 

  

```python
from sklearn.base import clone

forest = [clone(grid_search_cv.best_estimator_) for _ in range(n_trees)]

accuracy_scores = []

for tree, (X_mini_train, y_mini_train) in zip(forest, mini_sets):
    tree.fit(X_mini_train, y_mini_train) 
    
    y_pred = tree.predict(X_test)
accuracy_scores.append(accuracy_score(y_test, y_pred))

np.mean(accuracy_scores)
```

    =>	0.8496600000000001



*   랜덤포레스트를 구현하기 위해 만든 결정트리의 정확도보다 더 낮아졌습니다.
*   추가적으로 수정해줘야 합니다.

*   각 테스트 세트 샘플에 대해 500개의 결정 트리 예측을 만들고 다수로 나온 예측만 취합니다.(사이파이의 `mode()` 함수를 사용할 수 있습니다). 
*   그러면 테스트 세트에 대한 다수결 예측이 만들어집니다. 

```python
Y_pred = np.empty([n_trees, len(X_test)], dtype=np.uint8)

for tree_index, tree in enumerate(forest):
    Y_pred[tree_index] = tree.predict(X_test)

from scipy.stats import mode

y_pred_majority_votes, n_votes = mode(Y_pred, axis=0)
```

*   테스트 세트에서 이 예측을 평가합니다.
*   이전 정확도보다 0.5%가 오른걸 볼 수 있음

```python
accuracy_score(y_test, y_pred_majority_votes.reshape([-1]))
```

```python
=>	0.89
```

```python
from sklearn.ensemble import RandomForestClassifier

rnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, random_state=42)
rnd_clf.fit(X_train, y_train)

y_pred_rf = rnd_clf.predict(X_test)
```

```python
np.sum(y_pred == y_pred_rf) / len(y_pred) # almost identical predictions
```

```python
=>	0.92
```

- 7장의 랜덤포레스트 분류 모델과 직접 만든 랜덤 포레스트 모델과 비교한 결과 0.3%정도의 차이를 보인다.

  -이정도의 차이는 크지않아 비슷하다고 판별된다.

  



