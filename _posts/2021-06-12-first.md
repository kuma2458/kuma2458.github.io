### 기본설정

```python
# Python ≥3.5 is required
import sys
assert sys.version_info >= (3, 5)

# Scikit-Learn ≥0.20 is required
import sklearn
assert sklearn.__version__ >= "0.20"

# Common imports
import numpy as np
import os

# to make this notebook's output stable across runs
np.random.seed(42)

# To plot pretty figures
%matplotlib inline
import matplotlib as mpl
import matplotlib.pyplot as plt
mpl.rc('axes', labelsize=14)
mpl.rc('xtick', labelsize=12)
mpl.rc('ytick', labelsize=12)

# Where to save the figures
PROJECT_ROOT_DIR = "."
CHAPTER_ID = "decision_trees"
IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, "images", CHAPTER_ID)
os.makedirs(IMAGES_PATH, exist_ok=True)

def save_fig(fig_id, tight_layout=True, fig_extension="png", resolution=300):
    path = os.path.join(IMAGES_PATH, fig_id + "." + fig_extension)
    print("Saving figure", fig_id)
    if tight_layout:
        plt.tight_layout()
    plt.savefig(path, format=fig_extension, dpi=resolution)

from sklearn.datasets import load_iris
from sklearn.tree import DecisionTreeClassifier

iris = load_iris()
X = iris.data[:, 2:] # petal length and width
y = iris.target

tree_clf = DecisionTreeClassifier(max_depth=2, random_state=42)
tree_clf.fit(X, y)
```

# 1.랜덤 포레스트 모델 구현

### 데이터세트 준비

*   `make_moons(n_samples=500, noise=0.30)` 을 사용해 데이터셋을 생성합니다.

`random_state=42`를 추가해 동일한 결과가 나오도록 합니다.

```python
from sklearn.datasets import make_moons

X, y = make_moons(n_samples=500, noise=0.30, random_state=42)
```

*   `train_test_split()`을 사용해 훈련 세트와 테스트 세트로 나눕니다.

```python
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
```

### 결정트리 모델 준비

*  `DecisionTreeClassifier`의 최적의 매개변수를 찾기 위해 교차 검증과 함께 그리드 탐색을 수햅합니다(`GridSearchCV`를 사용하면 됩니다).



```python
from sklearn.model_selection import GridSearchCV

params = {'max_leaf_nodes': list(range(2, 100)), 'min_samples_split': [2, 3, 4]}
grid_search_cv = GridSearchCV(DecisionTreeClassifier(random_state=42), params, verbose=1, cv=3)

grid_search_cv.fit(X_train, y_train)

grid_search_cv.best_estimator_
```

```python
=>Fitting 3 folds for each of 294 candidates, totalling 882 fits
[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.
[Parallel(n_jobs=1)]: Done 882 out of 882 | elapsed:    1.3s finished
GridSearchCV(cv=3, error_score=nan,
             estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,
                                              criterion='gini', max_depth=None,
                                              max_features=None,
                                              max_leaf_nodes=None,
                                              min_impurity_decrease=0.0,
                                              min_impurity_split=None,
                                              min_samples_leaf=1,
                                              min_samples_split=2,
                                              min_weight_fraction_leaf=0.0,
                                              presort='deprecated',
                                              random_state=42,
                                              splitter='best'),
             iid='deprecated', n_jobs=None,
             param_grid={'max_leaf_nodes': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,
                                            13, 14, 15, 16, 17, 18, 19, 20, 21,
                                            22, 23, 24, 25, 26, 27, 28, 29, 30,
                                            31, ...],
                         'min_samples_split': [2, 3, 4]},
             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,
             scoring=None, verbose=1)
```

- 최적의 Max_leaf_nodes는 14로 나왔습니다.


*  찾은 매개변수를 사용해 전체 훈련 세트에 대해 모델을 훈련시키고 테스트 세트에서 성능을 측정합니다. 



기본적으로 `GridSearchCV`는 전체 교육 세트에 있는 최상의 모델을 교육하므로(`Refet=False`를 설정하여 변경할 수 있음) 다시 교육할 필요가 없습니다. 모델의 정확도를 간단하게 평가할 수 있습니다.

```python
from sklearn.metrics import accuracy_score

y_pred = grid_search_cv.predict(X_test)
accuracy_score(y_test, y_pred)
```

```python
=>	0.9
```

- 결정트리 모델의 정확도가 90%가 나온것을 알 수 있습니다.



### 랜덤포레스트 모델 구현

- 사이킷런의 `ShuffleSplit`을 사용해 나눴습니다.

```python
from sklearn.model_selection import ShuffleSplit

n_trees = 500 # 7장 랜덤포레스트 모델과 비교하기 위해 결정트리 개수를 500개로 통일함
n_instances = 100

mini_sets = []

rs = ShuffleSplit(n_splits=n_trees, test_size=len(X_train) - n_instances, random_state=42)
for mini_train_index, mini_test_index in rs.split(X_train):
    X_mini_train = X_train[mini_train_index]
    y_mini_train = y_train[mini_train_index]
    mini_sets.append((X_mini_train, y_mini_train))
```

* 이전 연습문제에서 찾은 최적의 매개변수를 사용해 각 서브셋에 결정 트리를 훈련시킵니다. 

* 최적의 매개변수는 Max_leaf_nodes = 14로 나왔습니다.

* 테스트 세트로 이 500개의 결정 트리를 평가합니다. 

  

```python
from sklearn.base import clone

forest = [clone(grid_search_cv.best_estimator_) for _ in range(n_trees)]

accuracy_scores = []

for tree, (X_mini_train, y_mini_train) in zip(forest, mini_sets):
    tree.fit(X_mini_train, y_mini_train) 
    
    y_pred = tree.predict(X_test)
accuracy_scores.append(accuracy_score(y_test, y_pred))

np.mean(accuracy_scores)
```

    =>	0.8496600000000001



*   랜덤포레스트를 구현하기 위해 만든 결정트리의 정확도보다 더 낮아졌습니다.
*   추가적으로 수정해줘야 합니다.

*   각 테스트 세트 샘플에 대해 500개의 결정 트리 예측을 만들고 다수로 나온 예측만 취합니다.(사이파이의 `mode()` 함수를 사용할 수 있습니다). 
*   그러면 테스트 세트에 대한 다수결 예측이 만들어집니다. 

```python
Y_pred = np.empty([n_trees, len(X_test)], dtype=np.uint8)

for tree_index, tree in enumerate(forest):
    Y_pred[tree_index] = tree.predict(X_test)

from scipy.stats import mode

y_pred_majority_votes, n_votes = mode(Y_pred, axis=0)
```

*   테스트 세트에서 이 예측을 평가합니다.
*   이전 정확도보다 0.5%가 오른걸 볼 수 있음

```python
accuracy_score(y_test, y_pred_majority_votes.reshape([-1]))
```

```python
=>	0.89
```

```python
from sklearn.ensemble import RandomForestClassifier

rnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, random_state=42)
rnd_clf.fit(X_train, y_train)

y_pred_rf = rnd_clf.predict(X_test)
```

```python
np.sum(y_pred == y_pred_rf) / len(y_pred) # almost identical predictions
```

```python
=>	0.92
```

- 7장의 랜덤포레스트 분류 모델과 직접 만든 랜덤 포레스트 모델과 비교한 결과 0.3%정도의 차이를 보인다.

  -이정도의 차이는 크지않아 비슷하다고 판별된다.

  

# 2번 문제

### MNIST 데이터셋 준비

---

- MNIST 데이터셋을 대상으로 차원축소를 진행하기 위해 먼저 MNIST 데이터셋을 불러온다. 

> `fetch_openml()` 함수는 지정된 데이터셋과 관련된 다양한 정보를 담은 사전(`Bunch` 객체) 객체를 반환하며,   
> 특성과 타깃 데이터셋은 각각 다음 키(key)의 값으로 지정되어 있다.

- `'data'` 키: 특성 데이터셋
- `'target'` 키: 타깃 데이터셋

```python
from sklearn.datasets import fetch_openml

mnist = fetch_openml('mnist_784', version=1, as_frame=False)
type(mnist)
```

- 아래 코드는 특성 데이터셋과 타깃 데이터셋 넘파이 어레이로 지정한다.

```python
mnist.target = mnist.target.astype(np.uint8)

X = mnist["data"]
y = mnist["target"]
```



### 데이터 셋에 차원축소 적용하기

---

- MNIST 데이터 세트를 6대 1비율로 훈련 세트와 테스트 세트로 나눕니다

- 10000개 : 60000개로 나눌경우 런타임이 매우 길어져 훈련세트의 샘플수를 2000으로 두고 1:6비율로 맞췄습니다

```python
np.random.seed(42)

m = 14000 # 훈련세트대 테스트세트의 비율을 1대6으로 맞추기 위해 14000개로 제한함
idx = np.random.permutation(60000)[:m] # 14000개 선택

n= 2000
X = mnist['data'][idx]
y = mnist['target'][idx]

X_train = X[:n]
X_test = X[n:]

y_train = y[:n]
y_test = y[n:]


```

### 각종 알고리즘으로 차원축소

---

#### PCA 알고리즘으로 차원축소

- PCA로 MNIST 데이터셋을 2차원으로 차원축소합니다.

```python
from sklearn.decomposition import PCA

pca = PCA(n_components=2, random_state=42)
X_train_pca_reduced = pca.fit_transform(X_train)
```

#### TSNE 알고리즘으로 차원축소 후 분류기 성능 평가

- 이제 t-SNE를 사용하여 차원을 2D로 줄여서 데이터 세트를 표시해 보겠습니다.
- 원래는 훈련세트를 1만개로 두고 했지만 TSNE 알고리즘을 적용할때 너무 오래걸려 이부분에서 샘플수를 조정했습니다
- TSNE은 transform() 메소드가 없어 fit_transform()을 사용 했습니다.

```python
from sklearn.manifold import TSNE

tsne = TSNE(n_components=2, random_state=42)
x_train_tsne_reduced = tsne.fit_transform(X_train)
```

#### LLE 알고리즘으로 2차원 차원축소 

```py
from sklearn.manifold import LocallyLinearEmbedding

lle = LocallyLinearEmbedding(n_components=2, random_state=42)
x_train_lle_reduced = lle.fit_transform(X_train)
```



### 각 데이터셋들로 분류기 훈련 후 성능평가

---

- 랜덤포레스트 분류기, 서포트 벡터 분류기 생성

```python
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

rnd_clf = RandomForestClassifier(n_estimators=100, random_state=42)
log_clf = LogisticRegression(multi_class="multinomial", solver="lbfgs", random_state=42)
```

### 1.PCA2차원 데이터 셋 평가

- 랜덤 포레스트 분류기 성능

```python
X_test_pca_reduced = pca.transform(X_test)

rnd_clf.fit(X_train_pca_reduced, y_train)

y_pred = rnd_clf.predict(X_test_pca_reduced)
accuracy_score(y_test, y_pred)
```

```python
=>0.40941666666666665
```

- 소프트 벡터 분류기 (SVC) 성능

```python
log_clf.fit(X_train_pca_reduced, y_train)
y_pred = log_clf.predict(X_test_pca_reduced)
accuracy_score(y_test, y_pred)
```

```python
=>0.42925
```

### 2.TSNE 2차원 데이터셋 평가

- 랜덤포레스트 분류기 성능

```python
X_test_tsne_reduced = tsne.fit_transform(X_test)

rnd_clf.fit(x_train_tsne_reduced, y1_train)

y_pred = rnd_clf.predict(X_test_reduced)
accuracy_score(y_test, y_pred)
```

```python
=>0.10575
```

- 소프트 벡터 분류기 (SVC) 성능

```python
log_clf.fit(x_train_tsne_reduced, y_train)
y_pred = log_clf.predict(X_test_tsne_reduced)
accuracy_score(y_test, y_pred)
```

```python
=>0.03333333333333333
```



### 3.LLE 2차원 데이터셋 평가

```python
X_test_lle_reduced = lle.transform(X_test)

rnd_clf.fit(x_train_lle_reduced, y_train)

y_pred = rnd_clf.predict(X_test_lle_reduced)
accuracy_score(y_test, y_pred)
```

```python
=>0.6796666666666666
```

- 소프트 벡터 분류기 (SVC) 성능

```python
log_clf.fit(x_train_lle_reduced, y_train)
y_pred = log_clf.predict(X_test_lle_reduced)
accuracy_score(y_test, y_pred)
```

```python
=>0.27016666666666667
```





### 종합평가

| 알고리즘 이름 | 랜덤포레스트        | SVC                 |
| ------------- | ------------------- | ------------------- |
| PCA           | 0.40941666666666665 | 0.42925             |
| TSNE          | 0.10575             | 0.03333333333333333 |
| LLE           | 0.6796666666666666  | 0.27016666666666667 |

- TSNE과 LLE은 SVC 평가점수가 최악인것을 볼수있다.
- MDS는 1시간을 돌렸지만 안되서 평가 제외했습니다



