---
title:  "과제7 차원축소 후 분류기 평가"
---



### 기본설정

```python
# Python ≥3.5 is required
import sys
assert sys.version_info >= (3, 5)

# Scikit-Learn ≥0.20 is required
import sklearn
assert sklearn.__version__ >= "0.20"

# Common imports
import numpy as np
import os

# to make this notebook's output stable across runs
np.random.seed(42)

# To plot pretty figures
%matplotlib inline
import matplotlib as mpl
import matplotlib.pyplot as plt
mpl.rc('axes', labelsize=14)
mpl.rc('xtick', labelsize=12)
mpl.rc('ytick', labelsize=12)

# Where to save the figures
PROJECT_ROOT_DIR = "."
CHAPTER_ID = "decision_trees"
IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, "images", CHAPTER_ID)
os.makedirs(IMAGES_PATH, exist_ok=True)

def save_fig(fig_id, tight_layout=True, fig_extension="png", resolution=300):
    path = os.path.join(IMAGES_PATH, fig_id + "." + fig_extension)
    print("Saving figure", fig_id)
    if tight_layout:
        plt.tight_layout()
    plt.savefig(path, format=fig_extension, dpi=resolution)

from sklearn.datasets import load_iris
from sklearn.tree import DecisionTreeClassifier

iris = load_iris()
X = iris.data[:, 2:] # petal length and width
y = iris.target

tree_clf = DecisionTreeClassifier(max_depth=2, random_state=42)
tree_clf.fit(X, y)
```

# 

# 2번 문제

### MNIST 데이터셋 준비

---

- MNIST 데이터셋을 대상으로 차원축소를 진행하기 위해 먼저 MNIST 데이터셋을 불러온다. 

> `fetch_openml()` 함수는 지정된 데이터셋과 관련된 다양한 정보를 담은 사전(`Bunch` 객체) 객체를 반환하며,   
> 특성과 타깃 데이터셋은 각각 다음 키(key)의 값으로 지정되어 있다.

- `'data'` 키: 특성 데이터셋
- `'target'` 키: 타깃 데이터셋

```python
from sklearn.datasets import fetch_openml

mnist = fetch_openml('mnist_784', version=1, as_frame=False)
type(mnist)
```

- 아래 코드는 특성 데이터셋과 타깃 데이터셋 넘파이 어레이로 지정한다.

```python
mnist.target = mnist.target.astype(np.uint8)

X = mnist["data"]
y = mnist["target"]
```



### 데이터 셋에 차원축소 적용하기

---

- MNIST 데이터 세트를 6대 1비율로 훈련 세트와 테스트 세트로 나눕니다

- 10000개 : 60000개로 나눌경우 런타임이 매우 길어져 훈련세트의 샘플수를 2000으로 두고 1:6비율로 맞췄습니다

```python
np.random.seed(42)

m = 14000 # 훈련세트대 테스트세트의 비율을 1대6으로 맞추기 위해 14000개로 제한함
idx = np.random.permutation(60000)[:m] # 14000개 선택

n= 2000
X = mnist['data'][idx]
y = mnist['target'][idx]

X_train = X[:n]
X_test = X[n:]

y_train = y[:n]
y_test = y[n:]


```

### 각종 알고리즘으로 차원축소

---

#### PCA 알고리즘으로 차원축소

- PCA로 MNIST 데이터셋을 2차원으로 차원축소합니다.

```python
from sklearn.decomposition import PCA

pca = PCA(n_components=2, random_state=42)
X_train_pca_reduced = pca.fit_transform(X_train)
```

#### TSNE 알고리즘으로 차원축소 후 분류기 성능 평가

- 이제 t-SNE를 사용하여 차원을 2D로 줄여서 데이터 세트를 표시해 보겠습니다.
- 원래는 훈련세트를 1만개로 두고 했지만 TSNE 알고리즘을 적용할때 너무 오래걸려 이부분에서 샘플수를 조정했습니다
- TSNE은 transform() 메소드가 없어 fit_transform()을 사용 했습니다.

```python
from sklearn.manifold import TSNE

tsne = TSNE(n_components=2, random_state=42)
x_train_tsne_reduced = tsne.fit_transform(X_train)
```

#### LLE 알고리즘으로 2차원 차원축소 

```py
from sklearn.manifold import LocallyLinearEmbedding

lle = LocallyLinearEmbedding(n_components=2, random_state=42)
x_train_lle_reduced = lle.fit_transform(X_train)
```



### 각 데이터셋들로 분류기 훈련 후 성능평가

---

- 랜덤포레스트 분류기, 서포트 벡터 분류기 생성

```python
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

rnd_clf = RandomForestClassifier(n_estimators=100, random_state=42)
log_clf = LogisticRegression(multi_class="multinomial", solver="lbfgs", random_state=42)
```

### 1.PCA2차원 데이터 셋 평가

- 랜덤 포레스트 분류기 성능

```python
X_test_pca_reduced = pca.transform(X_test)

rnd_clf.fit(X_train_pca_reduced, y_train)

y_pred = rnd_clf.predict(X_test_pca_reduced)
accuracy_score(y_test, y_pred)
```

```python
=>0.40941666666666665
```

- 소프트 벡터 분류기 (SVC) 성능

```python
log_clf.fit(X_train_pca_reduced, y_train)
y_pred = log_clf.predict(X_test_pca_reduced)
accuracy_score(y_test, y_pred)
```

```python
=>0.42925
```

### 2.TSNE 2차원 데이터셋 평가

- 랜덤포레스트 분류기 성능

```python
X_test_tsne_reduced = tsne.fit_transform(X_test)

rnd_clf.fit(x_train_tsne_reduced, y1_train)

y_pred = rnd_clf.predict(X_test_reduced)
accuracy_score(y_test, y_pred)
```

```python
=>0.10575
```

- 소프트 벡터 분류기 (SVC) 성능

```python
log_clf.fit(x_train_tsne_reduced, y_train)
y_pred = log_clf.predict(X_test_tsne_reduced)
accuracy_score(y_test, y_pred)
```

```python
=>0.03333333333333333
```



### 3.LLE 2차원 데이터셋 평가

```python
X_test_lle_reduced = lle.transform(X_test)

rnd_clf.fit(x_train_lle_reduced, y_train)

y_pred = rnd_clf.predict(X_test_lle_reduced)
accuracy_score(y_test, y_pred)
```

```python
=>0.6796666666666666
```

- 소프트 벡터 분류기 (SVC) 성능

```python
log_clf.fit(x_train_lle_reduced, y_train)
y_pred = log_clf.predict(X_test_lle_reduced)
accuracy_score(y_test, y_pred)
```

```python
=>0.27016666666666667
```





### 종합평가

| 알고리즘 이름 | 랜덤포레스트        | SVC                 |
| ------------- | ------------------- | ------------------- |
| PCA           | 0.40941666666666665 | 0.42925             |
| TSNE          | 0.10575             | 0.03333333333333333 |
| LLE           | 0.6796666666666666  | 0.27016666666666667 |

- TSNE과 LLE은 SVC 평가점수가 최악인것을 볼수있다.
- MDS는 1시간을 돌렸지만 안되서 평가 제외했습니다

